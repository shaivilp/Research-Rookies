{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "1. **Setup**:\n",
    "    - Import libraries and configure Polars settings.\n",
    "\n",
    "2. **Data Loading**:\n",
    "    - Load predictions, entries, stops, and patterns data from Parquet and JSON files.\n",
    "\n",
    "3. **Data Mapping and Formatting**:\n",
    "    - Define mappings for route IDs and status colors.\n",
    "    - Format and correct time columns in predictions data.\n",
    "\n",
    "4. **Data Processing**:\n",
    "    - Join stops data to entries data to get stop names.\n",
    "    - Filter and transform entries data to include only in-service records and calculate time differences.\n",
    "\n",
    "5. **Subset and Join Operations**:\n",
    "    - Filter data for specific route IDs and stops.\n",
    "    - Perform join operations to calculate time differences for stops ahead.\n",
    "\n",
    "6. **Descriptive Statistics**:\n",
    "    - Generate and display descriptive statistics for time differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "pl.enable_string_cache()\n",
    "pl.Config().set_tbl_cols(100)\n",
    "pl.Config().set_tbl_rows(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity = 'last_expr_or_assign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map route id to correct route name\n",
    "route_mapping = {\n",
    "    3: \"2L\",\n",
    "    4: \"2R\",\n",
    "    33: \"3\",\n",
    "    17: \"10\",\n",
    "    18: \"11\",\n",
    "    23: \"12\",\n",
    "    12: \"16\",\n",
    "    13: \"17\",\n",
    "    14: \"18\",\n",
    "    30: \"19\",\n",
    "    29: \"21\",\n",
    "    38: \"21 Tripper\",\n",
    "    777: \"777\"\n",
    "}\n",
    "\n",
    "#Map hex color to prediction status\n",
    "color_mapping = {\n",
    "    \"#cf1625\": \"Early\",\n",
    "    \"#39B139\": \"On Time\",\n",
    "    \"#D58803\": \"Little Late\",\n",
    "    \"#f3e413\": \"Very Late\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pl.read_parquet(\"./data/2024-09-preds.parquet\")\n",
    "\n",
    "preds = preds.with_columns(pl.col(\"statuscolor\").alias(\"statusName\"))\n",
    "preds = preds.with_columns(pl.col(\"statusName\").replace_strict(color_mapping))\n",
    "\n",
    "#Format the schedule time to be a datetime object\n",
    "preds = preds.with_columns(\n",
    "    pl.col('receiveTime').dt.convert_time_zone('America/Chicago'),\n",
    "    pl.col('schedule').alias('scheduleStr'),\n",
    "    pl.col('time').alias('timeStr'),\n",
    "    pl.col('schedule').str.to_time(format='%I:%M%p', strict=False),\n",
    "    pl.col('time').str.to_time(format='%I:%M%p', strict=False)\n",
    ")\n",
    "\n",
    "preds = preds.with_columns(pl.col('receiveTime').dt.combine(pl.col('time')).alias('time'),\n",
    "                    pl.col('receiveTime').dt.combine(pl.col('schedule')).alias('schedule'))\n",
    "\n",
    "#Correct for time columns hat are off by 24 hours\n",
    "preds = preds.with_columns(\n",
    "    pl.when(pl.col('time') - pl.col('receiveTime') > pl.duration(hours=12))\n",
    "    .then(pl.col('time') - pl.duration(hours=24))\n",
    "    .when(pl.col('time') - pl.col('receiveTime') < pl.duration(hours=-12))\n",
    "    .then(pl.col('time') + pl.duration(hours=24))\n",
    "    .otherwise(pl.col('time'))\n",
    "    .alias('time')\n",
    ")\n",
    "\n",
    "#Correct for schedule times columns that are off by 24 hours\n",
    "preds = preds.with_columns(\n",
    "    pl.when(pl.col('schedule') - pl.col('receiveTime') > pl.duration(hours=12))\n",
    "    .then(pl.col('schedule') - pl.duration(hours=24))\n",
    "    .when(pl.col('schedule') - pl.col('receiveTime') < pl.duration(hours=-12))\n",
    "    .then(pl.col('schedule') + pl.duration(hours=24))\n",
    "    .otherwise(pl.col('schedule'))\n",
    "    .alias('schedule')\n",
    ")\n",
    "\n",
    "# preds = preds.with_columns(\n",
    "#     (pl.col(\"time\") - pl.col(\"receiveTime\")).alias(\"predictedDiff\")\n",
    "# )\n",
    "\n",
    "# preds = preds.with_columns(\n",
    "#     (pl.col(\"schedule\") - pl.col(\"receiveTime\")).alias(\"scheduleDiff\")\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds['scheduleDiff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds['predictedDiff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(\"./data/2024-09-entries.parquet\")\n",
    "df = df.with_columns(pl.col(\"routeID\").replace_strict(route_mapping))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load stops data\n",
    "file = open(\"./data/stops.json\", \"r\")\n",
    "stopsData = json.load(file)\n",
    "\n",
    "stops = pl.DataFrame(stopsData['get_stops'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load patterns data\n",
    "pattern_mapping = {\n",
    "    3: \"2L\",\n",
    "    4: \"2R\",\n",
    "    37: \"3\",\n",
    "    17: \"10\",\n",
    "    18: \"11\",\n",
    "    23: \"12\",\n",
    "    12: \"16\",\n",
    "    13: \"17\",\n",
    "    14: \"18\",\n",
    "    33: \"19\",\n",
    "    46: \"21\",\n",
    "    45: \"21 Tripper\",\n",
    "}\n",
    "\n",
    "#Load patterns json\n",
    "file = open(\"./data/patterns.json\", \"r\")\n",
    "patternsData = json.load(file)\n",
    "\n",
    "patterns = pl.DataFrame(patternsData['get_patterns'])\n",
    "patterns = patterns.with_columns(pl.col(\"id\").replace_strict(pattern_mapping, default=\"None\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.rename({\"id\": \"nextStopID\"}).select([\"nextStopID\", \"name\"]).unique().sort(\"nextStopID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Left join stops to get stop names for nextStopID and lastStopID\n",
    "df = df.join(stops.rename({\"id\": \"nextStopID\"}).select([\"nextStopID\", \"name\"]).unique(), on=\"nextStopID\", how=\"left\").rename({\"name\": \"nextStopName\"})\n",
    "df = df.join(stops.rename({\"id\": \"lastStopID\"}).select([\"lastStopID\", \"name\"]).unique(), on=\"lastStopID\", how=\"left\").rename({\"name\": \"lastStopName\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out the subset of data we want to work with\n",
    "df = df.filter(\n",
    "    (pl.col(\"inService\"))\n",
    ")\n",
    "\n",
    "#Add stopChanged column\n",
    "df = df.with_columns(\n",
    "    (\n",
    "        (pl.col(\"lastStopID\") == pl.col(\"nextStopID\").shift(1)).over(\n",
    "            \"equipmentID\", order_by=\"receiveTime\"\n",
    "        )\n",
    "    ).alias(\"stopChanged\")\n",
    ")\n",
    "\n",
    "df = df.filter(pl.col(\"stopChanged\")).with_columns(\n",
    "    (pl.col(\"nextStopID\").shift(1) == pl.col(\"lastStopID\"))\n",
    "    .over(\"equipmentID\", order_by=\"receiveTime\")\n",
    "    .alias(\"nextToLast\")\n",
    ")\n",
    "\n",
    "#Add timeDiff column\n",
    "df = df.with_columns(\n",
    "    (-pl.col(\"receiveTime\").diff(-1).over(\"equipmentID\", order_by=\"receiveTime\")).alias(\n",
    "        \"timeDiff\"\n",
    "    )\n",
    ").filter(pl.col(\"nextToLast\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df.filter(\n",
    "    pl.col(\"routeID\") == \"2L\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = subset.filter(pl.col('nextStopID') == 465)\n",
    "df2 = subset.filter(pl.col('nextStopID') == 468)\n",
    "\n",
    "df2 = df2.with_columns(pl.col(\"receiveTime\").alias(\"receiveTime_right\"))\n",
    "joined_df = df1.join_asof(df2, on=\"receiveTime\", by='equipmentID', strategy='forward')\n",
    "\n",
    "joined_df = joined_df.with_columns(\n",
    "    (pl.col(\"receiveTime_right\") - pl.col(\"receiveTime\")).alias(\"timeDiff_3_stops_ahead\")\n",
    ")\n",
    "\n",
    "joined_df['routeID', 'equipmentID', 'lastStopName', 'nextStopName_right', 'receiveTime', 'receiveTime_right', 'timeDiff_3_stops_ahead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df = pl.read_parquet('./data/mega_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df['routeID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df['routeID', 'equipmentID', 'lastStopID', 'lastStopID_right', 'lastStopName', 'lastStopName_right',  'receiveTime', 'receiveTime_right', 'eta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pred_stopIds = mega_df['lastStopID', 'lastStopID_right'].unique().filter(pl.col('lastStopID_right').is_not_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join the subset on the triple key to get the correct prediction\n",
    "# m_predset = subset.join(\n",
    "#     preds,\n",
    "#     on=[\"equipmentID\", \"captureTime\"],\n",
    "#     how=\"inner\"\n",
    "# )\n",
    "\n",
    "# m_predset = m_predset['lastStopID', 'stopID'].unique()\n",
    "\n",
    "# m_pred_stopIds = m_pred_stopIds.rename({\"lastStopID_right\": \"stopID\"})\n",
    "\n",
    "# anti_join_set = m_pred_stopIds.join(\n",
    "#     m_predset,\n",
    "#     on=[\"lastStopID\", \"stopID\"],\n",
    "#     how=\"anti\"\n",
    "# )\n",
    "\n",
    "# anti_join_set = anti_join_set.join(stops.rename({\"id\": \"stopID\"}).select([\"stopID\", \"name\"]).unique(), on=\"stopID\", how=\"left\").rename({\"name\": \"nextStopName\"})\n",
    "# anti_join_set = anti_join_set.join(stops.rename({\"id\": \"lastStopID\"}).select([\"lastStopID\", \"name\"]).unique(), on=\"lastStopID\", how=\"left\").rename({\"name\": \"lastStopName\"})\n",
    "\n",
    "# anti_join_set = anti_join_set.sort(by='lastStopID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset['timeDiff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_predset = mega_df.join(\n",
    "    preds,\n",
    "    left_on=[\"equipmentID\", \"captureTime\", 'nextStopID_actual'],\n",
    "    right_on=[\"equipmentID\", \"captureTime\", 'stopID'],\n",
    "    how=\"inner\",\n",
    "    suffix=\"_pred\"\n",
    ")\n",
    "\n",
    "mega_predset = mega_predset.with_columns(\n",
    "    pl.col('receiveTime').dt.convert_time_zone('America/Chicago'),\n",
    ")\n",
    "\n",
    "mega_predset = mega_predset.with_columns(\n",
    "    (pl.col(\"time\") - pl.col(\"receiveTime\")).alias(\"predictedDiff\")\n",
    ")\n",
    "\n",
    "mega_predset = mega_predset.with_columns(\n",
    "    (pl.duration(minutes=pl.col('minutes'))).alias('minutes')\n",
    ")\n",
    "\n",
    "mega_predset = mega_predset.with_columns(\n",
    "    (pl.col(\"schedule\") - pl.col(\"receiveTime\")).alias(\"scheduleDiff\")\n",
    ")\n",
    "\n",
    "\n",
    "mega_predset['routeID', 'equipmentID', 'lat', 'lng', 'captureTime', 'stopID', 'lastStopID', 'nextStopID', 'lastStopName', 'nextStopName_actual', 'time', 'status', 'schedule', 'receiveTime', 'predictedDiff', 'timeDiff', 'scheduleDiff', 'minutesDiff', 'minutes', 'eta', 'statusName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a uniform column for nextStopPatternID\n",
    "subset = subset.with_columns(\n",
    "    pl.col(\"nextPatternStopID\").alias(\"patternStopID\")\n",
    ")\n",
    "\n",
    "#Join the subset on the triple key to get the correct prediction\n",
    "predSet = subset.join(\n",
    "    preds,\n",
    "    on=[\"equipmentID\", \"patternStopID\", \"captureTime\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "predSet = predSet.with_columns(\n",
    "    pl.col('receiveTime').dt.convert_time_zone('America/Chicago'),\n",
    ")\n",
    "\n",
    "#Subtract receiveTime and scheduleTime to get the time difference\n",
    "predSet = predSet.with_columns(\n",
    "    (pl.col(\"time\") - pl.col(\"receiveTime\")).alias(\"predictedDiff\")\n",
    ")\n",
    "\n",
    "predSet = predSet.with_columns(\n",
    "    (pl.col(\"schedule\") - pl.col(\"receiveTime\")).alias(\"scheduleDiff\")\n",
    ")\n",
    "\n",
    "predSet = predSet.with_columns(\n",
    "    (pl.col('predictedDiff') - pl.col('timeDiff')).alias('predictedActualDiff')\n",
    ")\n",
    "\n",
    "predSet = predSet.with_columns(\n",
    "    (pl.duration(minutes=pl.col('minutes'))).alias('minutes')\n",
    ")\n",
    "\n",
    "predSet = predSet.with_columns(\n",
    "    (pl.col('receiveTime') + (pl.col('minutes'))).alias('receiveTimePlusMinutes')\n",
    ")\n",
    "\n",
    "predSet = predSet.with_columns(\n",
    "    (pl.col('time') - pl.col('receiveTimePlusMinutes')).alias('receivePlusMinuteDiff')\n",
    ") \n",
    "\n",
    "predSet = predSet.with_columns(\n",
    "    (pl.col('timeDiff') - pl.col('minutes')).alias('minutesDiff')\n",
    ")\n",
    "\n",
    "#Filter out negative schedule differences\n",
    "# predSet = predSet.filter(\n",
    "#     (pl.col(\"scheduleDiff\").dt.total_minutes() >= 0) \n",
    "# )\n",
    "\n",
    "predSet['routeID', 'equipmentID', 'lat', 'lng', 'scheduleNumber', 'captureTime', 'stopID', 'lastStopID', 'nextStopID', 'lastStopName', 'nextStopName', 'time', 'status', 'schedule', 'receiveTime', 'receiveTimePlusMinutes', 'receivePlusMinuteDiff', 'predictedDiff', 'timeDiff', 'scheduleDiff', 'predictedActualDiff', 'minutesDiff', 'minutes', 'statusName']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_predset = predSet.filter(\n",
    "    (pl.col(\"routeID\") == \"2L\") &\n",
    "    (pl.col(\"timeDiff\") < pl.duration(minutes=20)) &\n",
    "    (pl.col(\"predictedDiff\") >= pl.duration(minutes=0))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcuate Metrics\n",
    "rmse = np.sqrt(mean_squared_error(r2_predset['predictedDiff'].to_numpy(), r2_predset['timeDiff'].to_numpy()))\n",
    "mae = mean_absolute_error(r2_predset['predictedDiff'].to_numpy(), r2_predset['timeDiff'].to_numpy())\n",
    "r2 = r2_score(r2_predset['predictedDiff'].to_numpy(), r2_predset['timeDiff'].to_numpy())\n",
    "print(f\"R2 Score: {r2}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_predset['predictedDiff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predSet['scheduleDiff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predSet['predictedActualDiff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffSet = predSet.filter(pl.col('scheduleDiff') < pl.duration(minutes=-30))\n",
    "\n",
    "diffSet['equipmentID', 'routeID', 'lastStopName', 'nextStopName', 'receiveTime', 'captureTime', 'schedule', 'time', 'scheduleDiff', 'timeDiff', 'predictedDiff', 'minutesDiff', 'predictedActualDiff', 'minutes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outset = predSet.filter(pl.col(\"predictedDiff\") < pl.duration(seconds=-30))\n",
    "\n",
    "outset['equipmentID', 'routeID', 'receiveTime', 'captureTime', 'schedule', 'time', 'timeDiff', 'predictedDiff', 'minutesDiff', 'predictedActualDiff', 'minutes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pl.lit(str(datetime.date.today()))\n",
    "\n",
    "data = preds[:2000]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the time and status time match or are on time\n",
    "#The Dateframe should be empty\n",
    "preds.filter(\n",
    "    (pl.col(\"time\") != pl.col(\"status\")) &\n",
    "    (pl.col(\"status\") != \"On Time\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if all the status color change togther\n",
    "(preds.group_by(\"equipmentID\", \"captureTime\")).agg(pl.col(\"statuscolor\").n_unique())['statuscolor'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predSet['scheduleDiff', 'statusName'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if our statusName column is correct by comparing it to the status column\n",
    "data.group_by(\"statusName\").agg(\n",
    "    pl.col(\"scheduleDiff\").min().alias(\"scheduleDiffMin\"),\n",
    "    pl.col(\"scheduleDiff\").max().alias(\"scheduleDiffMax\"),\n",
    "    pl.col(\"scheduleDiff\").mean().alias(\"scheduleDiffMean\"),\n",
    "    pl.col(\"scheduleDiff\").median().alias(\"scheduleDiffMedian\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull data for on time and little late statuses\n",
    "on_time_data = data.filter(pl.col('statusName') == 'On Time')\n",
    "little_late_data = data.filter(pl.col('statusName') == 'Little Late')\n",
    "\n",
    "#Convert the scheduleDiff to scheduleDiff_seconds\n",
    "on_time_data = on_time_data.with_columns(\n",
    "    (pl.col(\"scheduleDiff\").dt.total_seconds()).alias(\"scheduleDiff_seconds\") \n",
    ")\n",
    "\n",
    "little_late_data = little_late_data.with_columns(\n",
    "    (pl.col(\"scheduleDiff\").dt.total_seconds()).alias(\"scheduleDiff_seconds\") \n",
    ")\n",
    "\n",
    "\n",
    "# Plot the histograms\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.hist(on_time_data['scheduleDiff_seconds'].to_list(), bins=50, alpha=0.5, width=5, label='On time Schedule Diff')\n",
    "plt.hist(little_late_data['scheduleDiff_seconds'].to_list(), bins=50, alpha=0.5, width=5, label='Little Late Schedule Diff')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of On-time Schedule Diff')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for overlapping data in minutes\n",
    "threshold = 5.0 * 60\n",
    "\n",
    "# Filter out pairs where the difference in scheduleDiff_minutes is within the threshold\n",
    "overlapping_data = data.filter(pl.col('scheduleDiff').dt.total_seconds() >= threshold).sort('scheduleDiff')\n",
    "\n",
    "overlapping_data['routeID', 'equipmentID', 'receiveTime', 'schedule','statusName', 'scheduleDiff']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
