{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "1. **Importing Libraries and Configurations**:\n",
    "    - Import necessary libraries such as `polars`, `datetime`, and `json`.\n",
    "    - Configure `polars` settings for better performance and display.\n",
    "\n",
    "2. **Data Loading and Preprocessing**:\n",
    "    - Load route mappings to map route IDs to their respective names.\n",
    "    - Read and preprocess the main dataset from a Parquet file, replacing route IDs with their mapped names.\n",
    "    - Load and preprocess additional data from JSON files, including stops and patterns data.\n",
    "\n",
    "3. **Data Merging and Transformation**:\n",
    "    - Merge stops data with the main dataset to get stop names for `nextStopID` and `lastStopID`.\n",
    "    - Filter the dataset to include only relevant records and add new columns such as `stopChanged` and `timeDiff`.\n",
    "\n",
    "4. **Computing Permutations**:\n",
    "    - Define a function to compute permutations for each route, calculating time differences between stops.\n",
    "    - Save the resulting dataset to a Parquet file for further analysis.\n",
    "\n",
    "5. **Data Analysis**:\n",
    "    - Extract and display specific columns from the processed dataset for analysis.\n",
    "    - Filter and analyze data for specific routes and stops.\n",
    "\n",
    "6. **Alternative Approaches**:\n",
    "    - Document an alternative method to compute time differences between stops using the `shift` method (commented out).\n",
    "\n",
    "This notebook provides a comprehensive workflow for processing and analyzing transportation data, enabling detailed insights into bus routes and stop timings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import json\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "pl.enable_string_cache()\n",
    "pl.Config().set_tbl_cols(100)\n",
    "pl.Config().set_tbl_rows(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity = 'last_expr_or_assign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map route id to correct route name\n",
    "route_mapping = {\n",
    "    3: \"2L\",\n",
    "    4: \"2R\",\n",
    "    33: \"3\",\n",
    "    17: \"10\",\n",
    "    18: \"11\",\n",
    "    23: \"12\",\n",
    "    12: \"16\",\n",
    "    13: \"17\",\n",
    "    14: \"18\",\n",
    "    30: \"19\",\n",
    "    29: \"21\",\n",
    "    38: \"21 Tripper\",\n",
    "    777: \"777\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(\"./data/2024-09-entries.parquet\")\n",
    "df = df.with_columns(pl.col(\"routeID\").replace_strict(route_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load stops data\n",
    "file = open(\"./data/stops.json\", \"r\")\n",
    "stopsData = json.load(file)\n",
    "\n",
    "stops = pl.DataFrame(stopsData['get_stops'])\n",
    "\n",
    "#Load patterns data\n",
    "pattern_mapping = {\n",
    "    3: \"2L\",\n",
    "    4: \"2R\",\n",
    "    37: \"3\",\n",
    "    17: \"10\",\n",
    "    18: \"11\",\n",
    "    23: \"12\",\n",
    "    12: \"16\",\n",
    "    13: \"17\",\n",
    "    14: \"18\",\n",
    "    33: \"19\",\n",
    "    46: \"21\",\n",
    "    45: \"21 Tripper\",\n",
    "}\n",
    "\n",
    "#Load patterns json\n",
    "file = open(\"./data/patterns.json\", \"r\")\n",
    "patternsData = json.load(file)\n",
    "\n",
    "patterns = pl.DataFrame(patternsData['get_patterns'])\n",
    "patterns = patterns.with_columns(pl.col(\"id\").replace_strict(pattern_mapping, default=\"None\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.rename({\"id\": \"nextStopID\"}).select([\"nextStopID\", \"name\"]).unique().sort(\"nextStopID\")\n",
    "\n",
    "#Left join stops to get stop names for nextStopID and lastStopID\n",
    "df = df.join(stops.rename({\"id\": \"nextStopID\"}).select([\"nextStopID\", \"name\", \"lat\", \"lng\"]).unique(), on=\"nextStopID\", how=\"left\").rename({\"name\": \"nextStopName\", \"lat\": \"nextStopLat\", \"lng\": \"nextStopLng\"})\n",
    "df = df.join(stops.rename({\"id\": \"lastStopID\"}).select([\"lastStopID\", \"name\", \"lat\", \"lng\"]).unique(), on=\"lastStopID\", how=\"left\").rename({\"name\": \"lastStopName\", \"lat\": \"lastStopLat\", \"lng\": \"lastStopLng\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out the subset of data we want to work with\n",
    "df = df.filter(\n",
    "    (pl.col(\"inService\"))\n",
    ")\n",
    "\n",
    "#Add stopChanged column\n",
    "df = df.with_columns(\n",
    "    (\n",
    "        (pl.col(\"lastStopID\") == pl.col(\"nextStopID\").shift(1)).over(\n",
    "            \"equipmentID\", order_by=\"receiveTime\"\n",
    "        )\n",
    "    ).alias(\"stopChanged\")\n",
    ")\n",
    "\n",
    "df = df.filter(pl.col(\"stopChanged\")).with_columns(\n",
    "    (pl.col(\"nextStopID\").shift(1) == pl.col(\"lastStopID\"))\n",
    "    .over(\"equipmentID\", order_by=\"receiveTime\")\n",
    "    .alias(\"nextToLast\")\n",
    ")\n",
    "\n",
    "#Add timeDiff column\n",
    "df = df.with_columns(\n",
    "    (-pl.col(\"receiveTime\").diff(-1).over(\"equipmentID\", order_by=\"receiveTime\")).alias(\n",
    "        \"timeDiff\"\n",
    "    )\n",
    ").filter(pl.col(\"nextToLast\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_permutations():\n",
    "    mega_df = None\n",
    "    for route in route_mapping.values():\n",
    "\n",
    "        # Skip any inactive buses\n",
    "        if(route == \"777\"):\n",
    "            continue\n",
    "\n",
    "        subset = df.filter(pl.col('routeID') == route)\n",
    "        stop_ids = patterns.filter(pl.col(\"id\") == route)['stopIDs'][0]\n",
    "\n",
    "        print(f\"[!] Computing permutations for route: {route} with stop ids len: {len(stop_ids)}\")\n",
    "\n",
    "        for i in range(len(stop_ids)):\n",
    "            stop1 = stop_ids[i]\n",
    "            df1 = subset.filter(pl.col('lastStopID') == stop1)\n",
    "            \n",
    "            for j in range(1, 6):\n",
    "                stop2 = stop_ids[(i + j) % len(stop_ids)]\n",
    "                df2 = subset.filter(pl.col('lastStopID') == stop2)\n",
    "                \n",
    "                df2 = df2.with_columns(\n",
    "                    pl.col(\"receiveTime\").alias(\"receiveTime_right\"), \n",
    "                    pl.col('lastStopID').alias('nextStopID_actual'),\n",
    "                    pl.col('lastStopName').alias('nextStopName_actual')\n",
    "                )\n",
    "       \n",
    "                joined_df = df1.join_asof(df2, on=\"receiveTime\", by='equipmentID', strategy='forward')\n",
    "                \n",
    "                joined_df = joined_df.with_columns(\n",
    "                    (pl.col(\"receiveTime_right\") - pl.col(\"receiveTime\")).alias(f\"eta\")\n",
    "                )\n",
    "                \n",
    "                joined_df.drop([\"scheduleNumber_right\", \"nextStopName_right\", \"nextStopID_right\", \"aID_right\", \"trainID_right\", \"onSchedule_right\"], strict=True)\n",
    "                \n",
    "                #Add Time Of Day and Day of Week columns\n",
    "                joined_df = joined_df.with_columns(\n",
    "                    pl.col(\"receiveTime\").dt.hour().alias(\"hour_of_day\"),\n",
    "                    pl.col(\"receiveTime\").dt.minute().alias(\"minute_of_hour\"),\n",
    "                    pl.col(\"receiveTime\").dt.weekday().alias(\"day_of_week\"),\n",
    "                    pl.col(\"eta\").dt.total_seconds().alias(\"eta_seconds\")\n",
    "                )\n",
    "\n",
    "                if mega_df is None:\n",
    "                    mega_df = joined_df\n",
    "                else:\n",
    "                    mega_df = mega_df.vstack(joined_df)\n",
    "    \n",
    "    return mega_df\n",
    "\n",
    "mega_df = compute_permutations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the euclidean distance between the two stop locations\n",
    "def euclidean_distance(row):\n",
    "    R = 6371.0  # Earth's radius in km\n",
    "\n",
    "    lat1, lon1, lat2, lon2 = row[\"nextStopLat\"], row[\"nextStopLng\"], row[\"lastStopLat\"], row[\"lastStopLng\"]\n",
    "  \n",
    "    # Convert degrees to radians\n",
    "    lat1_rad, lon1_rad = math.radians(lat1), math.radians(lon1)\n",
    "    lat2_rad, lon2_rad = math.radians(lat2), math.radians(lon2)\n",
    "\n",
    "    # Approximate Euclidean distance\n",
    "    x1 = R * lat1_rad\n",
    "    y1 = R * lon1_rad\n",
    "    x2 = R * lat2_rad\n",
    "    y2 = R * lon2_rad\n",
    "\n",
    "    distance_km =  math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "    \n",
    "    # Convert to miles\n",
    "    return distance_km * 0.621371  \n",
    "  \n",
    "#Add distance column\n",
    "mega_df = mega_df.with_columns(\n",
    "    pl.struct([\"nextStopLat\", \"nextStopLng\", \"lastStopLat\", \"lastStopLng\"])\n",
    "    .map_elements(euclidean_distance, return_dtype=pl.Float32)\n",
    "    .alias(\"distance\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df.write_parquet('./data/mega_df.parquet')\n",
    "\n",
    "print(\"[X] Succesfully wrote mega_df to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df['routeID', 'equipmentID', 'lastStopID', 'nextStopID_actual', 'lastStopName', 'nextStopName_actual',  'receiveTime', 'receiveTime_right', 'eta', 'day_of_week', 'hour_of_day', 'minute_of_hour', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_l_mega_df = mega_df.filter(\n",
    "    pl.col('routeID') == '2L'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_l_mega_df.filter(pl.col('eta_seconds') > (60 * 20)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_l_mega_df.write_parquet('./data/two_l_mega_df_variance.parquet')\n",
    "print(\"[X] Succesfully wrote two_l_mega_df to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twelve_route_mega_df = mega_df.filter(\n",
    "    pl.col('routeID') == '12',\n",
    "    pl.col('eta_seconds') < (60 * 35)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twelve_route_mega_df.filter(pl.col('eta_seconds') > (60 * 35)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twelve_route_mega_df.write_parquet('./data/twelve_route_mega_df.parquet')\n",
    "print(\"[X] Succesfully wrote two_l_mega_df and twelve_route_mega_df to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way to compute n stops ahead with some caviates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Approach #2 - Using the 'shift' method to calculate the time difference between two stops (Not recommended)\n",
    "# # Calcuate the time difference between going to Linchon hall to Stevenson South\n",
    "# shiftVal = -3\n",
    "# startingStop = 465\n",
    "# subset = df.filter(pl.col(\"routeID\") == \"2L\")\n",
    "\n",
    "# # Ensure the data is sorted by 'equipmentID' and 'receiveTime'\n",
    "# df = subset.sort([\"equipmentID\", \"receiveTime\"])\n",
    "\n",
    "# # Group by 'equipmentID' and shift the 'receiveTime' column by 3 to get the time three stops ahead\n",
    "# df = df.with_columns([\n",
    "#     pl.col(\"receiveTime\").shift(shiftVal).over(\"equipmentID\").alias(\"receiveTime_3_stops_ahead\"),\n",
    "#     pl.col(\"nextStopID\").shift(shiftVal).over(\"equipmentID\").alias(\"nextStopID_3_stops_ahead\"),\n",
    "#     pl.col(\"lastStopName\").shift(shiftVal).over(\"equipmentID\").alias(\"lastStopName_3_stops_ahead\")\n",
    "# ])\n",
    "\n",
    "# # Join with stops to get the name of the stop 3 stops ahead\n",
    "# df = df.join(stops.rename({\"id\": \"nextStopID_3_stops_ahead\"}).select([\"nextStopID_3_stops_ahead\", \"name\"]).unique(), on=\"nextStopID_3_stops_ahead\", how=\"left\").rename({\"name\": \"nextStopName_3_ahead\"})\n",
    "\n",
    "# # Filter the rows where 'nextStopID' is 433 to calculate the time difference\n",
    "# df_filtered = df.filter(pl.col(\"nextStopID\") == startingStop)\n",
    "\n",
    "# df_filtered = df_filtered.with_columns([\n",
    "#     pl.col(\"receiveTime\").dt.convert_time_zone(\"America/Chicago\").alias(\"receiveTime\"),\n",
    "#     pl.col(\"receiveTime_3_stops_ahead\").dt.convert_time_zone(\"America/Chicago\").alias(\"receiveTime_3_stops_ahead\")\n",
    "# ])\n",
    "\n",
    "# # Calculate the time difference between the current stop and three stops ahead\n",
    "# df_filtered = df_filtered.with_columns([\n",
    "#     (pl.col(\"receiveTime_3_stops_ahead\") - pl.col(\"receiveTime\")).alias(\"timeDiff_3_stops_ahead\")\n",
    "# ])\n",
    "\n",
    "# # Display the result\n",
    "# df_filtered['routeID', 'equipmentID', 'lastStopName', 'nextStopName_3_ahead', 'receiveTime', 'receiveTime_3_stops_ahead', 'timeDiff_3_stops_ahead']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
